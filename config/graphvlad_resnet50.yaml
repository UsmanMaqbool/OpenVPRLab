# ----------------------------------------------------------------------------
# Copyright (c) 2024 Amar Ali-bey
# # https://github.com/amaralibey/OpenVPRLab
# Licensed under the MIT License. See LICENSE file in the project root.
# ----------------------------------------------------------------------------


#---------------------------------------------------
# Datamodule Configuration
#---------------------------------------------------
datamodule:
  train_set_name: "gsv-cities-light" # use "gsv-cities" if you have downloaded the full dataset
  train_image_size: 
    - 320
    - 320
  img_per_place: 4
  batch_size: 10
  num_workers: 8
  val_set_names:
    - "msls-val"
    - "pitts30k-val"

#---------------------------------------------------
# VPR Model Configuration
#---------------------------------------------------
segmentation:
  module: src.models.backbones
  class: FastSCNN    # class name in the __init__.py file in the aggregators directory
  fastscnn: "/home/m.maqboolbhutta/usman_ws/datasets/official/fast_scnn/fast_scnn_citys.pth"
  params:
    num_classes: 19
  

backbone:
  module: src.models.backbones
  class: ResNet
  params:
    backbone_name: "resnet50"  # name of the resnet backbone (see ResNet.AVAILABLE_MODELS)
    pretrained: true
    num_unfrozen_blocks: 1
    crop_last_block: true
  
  # Example of DinoV2
  # module: src.models.backbones
  # class: DinoV2
  # params:
  #   backbone_name: "dinov2_vitb14" # name of the vit backbone (see DinoV2.AVAILABLE_MODELS)
  #   num_unfrozen_blocks: 2

aggregator:
  module: src.models.aggregators # module path
  class: NetVLAD    # class name in the __init__.py file in the aggregators directory
  graphvlad: True
  params:
    clusters_num: 16
    alpha: 100.0
    dim: 1024
  

  # Example of MixVPR
  # module: src.models.aggregators
  # class: MixVPR   # class name
  # params:
  #   in_channels: 1024   # we will derive this from the backbone.
  #   in_h: 20            # input height (this depends on the input image size and the backbone)
  #   in_w: 20
  #   out_channels: 512
  #   mix_depth: 4
  #   mlp_ratio: 1
  #   out_rows: 4

#---------------------------------------------------
# Loss Function Configuration
#---------------------------------------------------
loss_function: 
  # check src/losses/vpr_losses.py for available loss functions, we are using pytorch_metric_learning library
  # if you want to develop your own loss function, you can add it to the vpr_losses.py file
  # or create a new file in the losses directory and import it into the __inin__.py file
  module: src.losses
  class: VPRLossFunction
  params:
    loss_fn_name: "MultiSimilarityLoss"   # other possible values: "MultiSimilarityLoss", "SupConLoss", "ContrastiveLoss", "TripletMarginLoss"
    miner_name: "MultiSimilarityMiner"    # other possible values: "MultiSimilarityMiner", "TripletMarginMiner", "PairMarginMiner"


#---------------------------------------------------
# Trainer Configuration
#---------------------------------------------------
trainer:
  optimizer: adamw
  lr: 0.0002      # learning rate
  wd: 0.001       # weight decay
  warmup: 1500    # linear warmup steps
  max_epochs: 40
  milestones:
    - 10
    - 20
    - 30
  lr_mult: 0.1 # learning rate multiplier at each milestone
